# -*- coding: utf-8 -*-
"""
Created on Fri May  6 15:37:00 2022

@author: kumarz
"""

from gensim.models.doc2vec import Doc2Vec
from nltk.tokenize import word_tokenize

import pandas as pd

import requests
from requests.auth import HTTPBasicAuth
import json

import os
import time
import logging

from config import JIRA_ACCOUNT,JIRA_PWD,JIRA_URL,JQL,SIMILARITY_THRESHOLDS,MAX_RECOMMENDING_JIRA_NUM,RECOMMEND_THRESHOLDS
from config import set_logger

logger = logging.getLogger(__name__)

auth = HTTPBasicAuth(JIRA_ACCOUNT,JIRA_PWD)
headers = {"Accept": "application/json"}

def getSingleJIRA(jiraID):    
    url = JIRA_URL + 'issue/' + jiraID
    response = requests.request("GET", url, headers=headers,auth=auth)
    projectIssue = json.dumps(json.loads(response.text),sort_keys=False,indent=4,separators=(",", ": "))
    issue = json.loads(projectIssue)
    summary_content = issue["fields"]["description"]
    default_content = "Please enter the fault support description here      Please provide any details you find relevant about the customer environment here E.g.       Product cluster and configuration    Hosting Labs    Its composition    Hardware virtualized environment details    OS    Networking    Hotfixes workaround applied    TSN applied    Etc..."
    if default_content in preHandle(summary_content):
        summary_content = ""
        logger.warning(f" There is no input given under description section: {jiraID}")
    if "customfield_37638" in issue["fields"] and issue["fields"]["customfield_37638"] is not None:
        summary_content = " " + issue["fields"]["customfield_37638"]
    return {'jiraid': issue["key"], 'title': preHandle(issue["fields"]["summary"]), 'summary': preHandle(summary_content)}

def getClonedIssue(issue):
    cloned_Issue = ""
    if issue["fields"]["issuelinks"] is not None and len(issue["fields"]["issuelinks"]) != 0:      
        if "inwardIssue" in issue["fields"]["issuelinks"][0]:
            cloned_Issue = issue["fields"]["issuelinks"][0]["inwardIssue"]["key"]
        elif "outwardIssue" in issue["fields"]["issuelinks"][0]:
            cloned_Issue = issue["fields"]["issuelinks"][0]["outwardIssue"]["key"]
    return cloned_Issue

def iterateDictIssues(issue):
    cloned_Issue = getClonedIssue(issue)
    summary_content = issue["fields"]["description"]
    default_content = "Please enter the fault support description here      Please provide any details you find relevant about the customer environment here E.g.       Product cluster and configuration    Hosting Labs    Its composition    Hardware virtualized environment details    OS    Networking    Hotfixes workaround applied    TSN applied    Etc..."
    if default_content in preHandle(summary_content):
        summary_content = ""
    if "customfield_37638" in issue["fields"] and issue["fields"]["customfield_37638"] is not None:
        summary_content = " " + issue["fields"]["customfield_37638"]
    ticket_dict = {'jiraid': issue["key"], 'title': issue["fields"]["summary"], 'summary': summary_content, 'cloned_Issue': cloned_Issue}
    return ticket_dict

def preHandle(txt):
    txt=txt.replace("\n", " ")
    txt=txt.replace("--", " ")
    txt=txt.replace("===", " ")
    txt=txt.replace(". ", " ")
    txt=txt.replace('\t',' ').replace('\r\n',' ').replace('\r',' ')
    for ch in '~!@#$%^&*()+"{}[]|?<>\'/:;_':
        txt=txt.replace(ch," ")
    return txt

def filter_crawler(dictProjectIssues):
    tickets_corpus = []
    for key, value in dictProjectIssues.items():
        if(key == "issues"):
            totalIssues = len(value)
            for eachIssue in range(totalIssues):
                tickets_corpus.append(iterateDictIssues(value[eachIssue]))
    return tickets_corpus

def addComment2JIRA(jiraID, recomendedJIRAList, clonedJIRA):    
    url = JIRA_URL + 'issue/' + jiraID + '/comment'
    headers = {"Accept": "application/json","Content-Type": "application/json"}
    commentHeader = "Please verify following tickets similar to the issue:\n \n"
    commentTail = """
              ATTENTION! Does above recommended JIRA help you to find the resolution? 
              If yes please kindly give us thumbsup by click smile face below, it will help ML Robot to improve the predication accuracy.

--- Disclaimer: this is automatic note generated by Register Machine Learning Robot.\n
            """
    commentBody = ""
    number = 1
    data = ""
    for ticket in recomendedJIRAList:
        if ticket == clonedJIRA:
            logger.warning(f" This ticket: {jiraID} is cloned from {ticket}, ignore it")
            break
        commentBody += ticket
        commentBody += ": "
        commentBody += getSingleJIRA(ticket)["title"]
        commentBody += "\n"
        number += 1
        if number > MAX_RECOMMENDING_JIRA_NUM:
            break
        data = json.dumps({"body": commentHeader + commentBody + commentTail})
        logger.warning(f" Add comment to {jiraID} with similar ticket: {ticket}")
        requests.request("POST", url, headers=headers,data=data,auth=auth)
        commentBody = ""

def getRecomendedJIRAList(dataFrame):
    targetJIRA = dataFrame.loc[0]["For"]
    relatedJIRADictionaries = {}
    relatedJIRAList = []
    for i in range(1, len(dataFrame)):
        #logger.warning(f"model {dataFrame.loc[i]['Modelname']} with similarity {dataFrame.loc[i]['Related-Tickets']} ")
        ticketsListOfSingleModel = dataFrame.loc[i]["Related-Tickets"].split(":")
        for ticket in ticketsListOfSingleModel:
            ticketNo = ticket.split("|")[0][1:]
            similarity_ratio = ticket.split("|")[1][0:-1]
            if ticketNo == targetJIRA or SIMILARITY_THRESHOLDS > float(similarity_ratio):
                continue
            if ticketNo in relatedJIRADictionaries:
                relatedJIRADictionaries[ticketNo] += 1
            else:
                relatedJIRADictionaries[ticketNo] = 1
    for key,value in sorted(relatedJIRADictionaries.items(),key=lambda item:item[1], reverse=True):
        if value >= int(RECOMMEND_THRESHOLDS):
            relatedJIRAList.append(key)
    if len(relatedJIRAList) > 0:
        isExists=os.path.exists("csv")
        if not isExists:
            os.makedirs("csv")
        df.to_csv(f'./csv/{targetJIRA}.csv', index=False)
    return relatedJIRAList
        
def getLatestJIRA():
    time.sleep(300)
    url = JIRA_URL + 'search'
    query = {
        'jql': JQL + ' and created >= startOfDay("-5m")',
        'startAt': 0,
        'maxResults': 50,
    }
    response = requests.request("GET", url, headers=headers,auth=auth,params=query)
    if len(response.text) > 0:
        projectIssues = json.dumps(json.loads(response.text),sort_keys=True,indent=4,separators=(",", ": "))
        dictProjectIssues = json.loads(projectIssues)
        jiraList = filter_crawler(dictProjectIssues)
        return jiraList
    else:
        return []

if __name__ == '__main__':
    set_logger("jira_Recommending")
    foundedJiraList = []
    while True:
        jiraList = []
        try:      
            jiraList = getLatestJIRA()
            if len(jiraList) != 0:
                for jira_Dic in jiraList:
                    targetJIRA = jira_Dic["jiraid"]
                    clonedJIRA = jira_Dic["cloned_Issue"]
                    if targetJIRA in foundedJiraList:
                        continue
                    else:
                        foundedJiraList.append(targetJIRA)
                        logger.warning(f" New created JIRA found: {targetJIRA}")
                        df = pd.DataFrame({'Modelname':['TestModel'], 'For':[targetJIRA], 'Related-Tickets':['JIRA_ID|Similarity;JIRA_ID|Similarity'], 'Points':[-10]})
                        models_list = [                                                                    
                                   "1_summary_d2v_0dm_100epoch_50vecsize_0.025alpha.model",
                                   "1_summary_d2v_1dm_100epoch_50vecsize_0.025alpha.model",
                                   "1_summary_d2v_0dm_100epoch_100vecsize_0.025alpha.model", 
                                   "1_summary_d2v_1dm_100epoch_100vecsize_0.025alpha.model",
                                   "1_summary_d2v_0dm_100epoch_200vecsize_0.025alpha.model", 
                                   "1_summary_d2v_1dm_100epoch_200vecsize_0.025alpha.model",
                                   "1_summary_d2v_0dm_500epoch_50vecsize_0.025alpha.model", 
                                   "1_summary_d2v_1dm_500epoch_50vecsize_0.025alpha.model",
                                   "1_summary_d2v_0dm_500epoch_100vecsize_0.025alpha.model", 
                                   "1_summary_d2v_1dm_500epoch_100vecsize_0.025alpha.model",
                                   "1_summary_d2v_0dm_500epoch_200vecsize_0.025alpha.model", 
                                   "1_summary_d2v_1dm_500epoch_200vecsize_0.025alpha.model"]
                        for modelname in models_list:
                            model = Doc2Vec.load("./models/"+str(modelname))
                            data_dict = {}
                            test_issue_text_data = ''
                            data_dict['Modelname'] = modelname
                            data_dict['Points'] = 0
                            data_dict['For'] = jira_Dic["jiraid"]
                            test_issue_text_data += str(jira_Dic["title"])
                            test_issue_text_data += str(jira_Dic["summary"])
        
                            test_data = word_tokenize(test_issue_text_data.lower())
                            test_issue_vector = model.infer_vector(test_data)
                            similar_doc = model.dv.most_similar(positive=[test_issue_vector], topn=10)
                            data_dict['Related-Tickets'] = ":".join(["("+str(doc)+"|"+str("{0:.3f}".format(similar_score))+")" for (doc,similar_score) in similar_doc])
                            df.loc[df.index.max() + 1] = data_dict
                        addComment2JIRA(targetJIRA, getRecomendedJIRAList(df), clonedJIRA)
            else:
                continue
        except Exception as e:
            logger.error(f" got an error, ignore it and keep looping {e}")

